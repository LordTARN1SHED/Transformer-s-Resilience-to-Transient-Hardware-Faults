{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8a51eec-74df-4c53-a8a8-104b5532ab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /datasets/tatoeba/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /datasets/Helsinki-NLP/tatoeba/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: s3.amazonaws.com\n",
      "DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/tatoeba/tatoeba.py HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /datasets/tatoeba/resolve/00476f0f7e251c934e14f6e88c42a15e1b67c5a5/dataset_infos.json HTTP/1.1\" 307 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /datasets/Helsinki-NLP/tatoeba/resolve/00476f0f7e251c934e14f6e88c42a15e1b67c5a5/dataset_infos.json HTTP/1.1\" 404 0\n",
      "DEBUG:filelock:Attempting to acquire lock 36951872736 on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Lock 36951872736 acquired on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Attempting to release lock 36951872736 on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Lock 36951872736 released on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 15575079840 on /Users/lordtarn1shed/.cache/huggingface/datasets/_Users_lordtarn1shed_.cache_huggingface_datasets_tatoeba_en-fr-lang1=en,lang2=fr_0.0.0_b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6.lock\n",
      "DEBUG:filelock:Lock 15575079840 acquired on /Users/lordtarn1shed/.cache/huggingface/datasets/_Users_lordtarn1shed_.cache_huggingface_datasets_tatoeba_en-fr-lang1=en,lang2=fr_0.0.0_b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6.lock\n",
      "DEBUG:fsspec.local:open file: /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6/dataset_info.json\n",
      "DEBUG:filelock:Attempting to release lock 15575079840 on /Users/lordtarn1shed/.cache/huggingface/datasets/_Users_lordtarn1shed_.cache_huggingface_datasets_tatoeba_en-fr-lang1=en,lang2=fr_0.0.0_b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6.lock\n",
      "DEBUG:filelock:Lock 15575079840 released on /Users/lordtarn1shed/.cache/huggingface/datasets/_Users_lordtarn1shed_.cache_huggingface_datasets_tatoeba_en-fr-lang1=en,lang2=fr_0.0.0_b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 20700251472 on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Lock 20700251472 acquired on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Attempting to release lock 20700251472 on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Lock 20700251472 released on /Users/lordtarn1shed/.cache/huggingface/modules/datasets_modules/datasets/tatoeba.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 36952139056 on /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6_builder.lock\n",
      "DEBUG:filelock:Lock 36952139056 acquired on /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6_builder.lock\n",
      "DEBUG:fsspec.local:open file: /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6/dataset_info.json\n",
      "DEBUG:filelock:Attempting to release lock 36952139056 on /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6_builder.lock\n",
      "DEBUG:filelock:Lock 36952139056 released on /Users/lordtarn1shed/.cache/huggingface/datasets/tatoeba/en-fr-lang1=en,lang2=fr/0.0.0/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6_builder.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /t5-small/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from src import tensorfi2 as tfi\n",
    "\n",
    "# 1. 下载 Tatoeba 英法并只取前 1% 样本以加速实验\n",
    "raw = load_dataset(\"tatoeba\", lang1=\"en\", lang2=\"fr\", split=\"train[:1%]\")  # Tatoeba 英法平行语料 :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "# 2. 初始化分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# 3. 预处理：添加翻译前缀，tokenize，并将 padding token 转为 -100 以忽略\n",
    "def preprocess(examples):\n",
    "    inputs  = [\"translate English to French: \" + ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    mi = tokenizer(inputs,  max_length=64, truncation=True, padding=\"max_length\")\n",
    "    lbl = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\").input_ids\n",
    "    lbl = [[(t if t != tokenizer.pad_token_id else -100) for t in seq] for seq in lbl]\n",
    "    mi[\"labels\"] = lbl\n",
    "    return mi\n",
    "\n",
    "tokenized = raw.map(preprocess, batched=True, remove_columns=[\"translation\"])  # 动态预处理 :contentReference[oaicite:5]{index=5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58b57ec6-156d-442d-8f7b-fe506609e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /t5-small/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "\n",
    "# 可定制的超参数\n",
    "MODEL_CHECKPOINT = \"t5-small\"   # 可换成 t5-base、t5-large 等 :contentReference[oaicite:6]{index=6}\n",
    "LEARNING_RATE     = 5e-5\n",
    "NUM_BEAMS         = 4\n",
    "\n",
    "# 加载模型\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)  # 加载预训练 T5 编码器-解码器 :contentReference[oaicite:7]{index=7}\n",
    "\n",
    "# 若需调整层数 / 头数，可在此处重新定义 config\n",
    "# e.g., model.config.num_layers = 4; model.config.num_heads = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71eb64ae-9150-485b-9900-d942eab3c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.19.0\n",
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 166/166 [01:23<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation Loss after epoch 1: 0.2177095115184784\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 166/166 [01:22<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Validation Loss after epoch 2: 0.2177095115184784\n"
     ]
    }
   ],
   "source": [
    "# 若未来可用，可取消注释\n",
    "#from tensorflow.keras import mixed_precision\n",
    "# mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# 1. 环境检测\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Physical devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# 2. Optimizer & Loss\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "lambda_weight = 0.0\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "\n",
    "tf_train = (\n",
    "    tokenized\n",
    "    .to_tf_dataset(\n",
    "        columns=[\"input_ids\",\"attention_mask\",\"labels\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False      # 先关掉 to_tf_dataset 内部的 shuffle\n",
    "    )\n",
    "    .cache()               # 缓存所有样本（已按顺序）\n",
    "    .shuffle(1000, reshuffle_each_iteration=True)  # 关键参数        # 每个 epoch 在缓存上再打乱\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "tf_test = tokenized.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ").cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "@tf.function  # 普通编译，无 JIT\n",
    "def train_step(inputs, masks, labels, lam):\n",
    "    with tf.GradientTape() as outer, tf.GradientTape() as inner:\n",
    "        outputs = model(inputs,\n",
    "                        attention_mask=masks,\n",
    "                        labels=labels,\n",
    "                        training=True)\n",
    "        loss = outputs.loss\n",
    "    grads = inner.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # CPU 上 L1 正则聚合\n",
    "    with tf.device('/CPU:0'):\n",
    "        penalties = [\n",
    "            tf.reduce_sum(tf.abs(tf.cast(g, tf.float32))) / tf.cast(tf.size(g), tf.float32)\n",
    "            for g in grads if g is not None\n",
    "        ]\n",
    "        robust_pen = tf.reduce_sum(penalties) * lam\n",
    "\n",
    "    total_loss = loss + robust_pen\n",
    "    final_grads = outer.gradient(\n",
    "        total_loss,\n",
    "        model.trainable_variables,\n",
    "        unconnected_gradients=tf.UnconnectedGradients.ZERO\n",
    "    )\n",
    "    clipped = [tf.clip_by_value(g, -1.0, 1.0) for g in final_grads]  # 更温和的裁剪\n",
    "    optimizer.apply_gradients(zip(clipped, model.trainable_variables))\n",
    "    del tape  # 显式释放持久化 Tape\n",
    "    return loss\n",
    "\n",
    "# --- 训练循环 ---\n",
    "N = len(tokenized)\n",
    "steps_per_epoch = math.ceil(N / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    if epoch >= 1:\n",
    "        lambda_weight = 0.1\n",
    "\n",
    "    # 重置指标 & 迭代器\n",
    "    train_metric = tf.keras.metrics.Mean()\n",
    "    # 方案1：显式迭代器\n",
    "    train_iter = iter(tf_train)\n",
    "\n",
    "    pbar = tqdm(range(steps_per_epoch), desc=\"Training\")\n",
    "    for step in pbar:\n",
    "        # 取下一批\n",
    "        batch = next(train_iter)\n",
    "        loss = train_step(batch[\"input_ids\"],\n",
    "                          batch[\"attention_mask\"],\n",
    "                          batch[\"labels\"],\n",
    "                          lambda_weight)\n",
    "        train_metric.update_state(loss)\n",
    "\n",
    "        \"\"\"\n",
    "        # 将 loss.numpy() 转为 float\n",
    "        loss_val   = loss.numpy().item()\n",
    "        robust_val = (robust_loss).numpy().item()\n",
    "        pbar.set_postfix({\n",
    "            \"loss\":   f\"{loss_val:.4f}\",\n",
    "            \"robust_loss\": f\"{robust_val:.4f}\"\n",
    "        })\n",
    "        \"\"\"\n",
    "        \n",
    "    # 5.2 验证\n",
    "    val_metric = tf.keras.metrics.Mean()\n",
    "    for batch in tf_test:\n",
    "        outputs  = model(batch[\"input_ids\"],\n",
    "                         attention_mask=batch[\"attention_mask\"],\n",
    "                         labels=batch[\"labels\"],\n",
    "                         training=False)\n",
    "        val_loss = loss_fn(batch[\"labels\"], outputs.logits)\n",
    "        val_metric.update_state(val_loss)\n",
    "    print(f\">>> Validation Loss after epoch {epoch + 1}: {val_metric.result().numpy()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1516bc39-bcef-4713-bc72-78b726e4c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lordtarn1shed/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Il s'agit d'un essai.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "# 推理示例\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "sample = \"translate English to French: This is a test.\"\n",
    "inp = tokenizer(sample, return_tensors=\"tf\", padding=\"max_length\", max_length=64)\n",
    "with tf.device('/CPU:0'):\n",
    "    out = model.generate(inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"], num_beams=NUM_BEAMS)\n",
    "print(\"Translation:\", tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da3f9168-b564-4798-b476-8a4c904e44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logging level set to DEBUG\n",
      "INFO:root:Starting fault injection in user-specified layer 1\n",
      "INFO:root:Completed injections... exiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable layers (variables): 131\n",
      "[Layer 0] Name: shared/shared/embeddings:0, Shape: (32128, 512), Elements: 16449536\n",
      "[Layer 1] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0, Shape: (32, 8), Elements: 256\n",
      "[Layer 2] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 3] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 4] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 5] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 6] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 7] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 8] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 9] Name: tft5_for_conditional_generation_18/encoder/block_._0/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 10] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 11] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 12] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 13] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 14] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 15] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 16] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 17] Name: tft5_for_conditional_generation_18/encoder/block_._1/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 18] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 19] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 20] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 21] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 22] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 23] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 24] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 25] Name: tft5_for_conditional_generation_18/encoder/block_._2/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 26] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 27] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 28] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 29] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 30] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 31] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 32] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 33] Name: tft5_for_conditional_generation_18/encoder/block_._3/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 34] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 35] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 36] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 37] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 38] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 39] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 40] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 41] Name: tft5_for_conditional_generation_18/encoder/block_._4/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 42] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 43] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 44] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 45] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 46] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 47] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 48] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 49] Name: tft5_for_conditional_generation_18/encoder/block_._5/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 50] Name: tft5_for_conditional_generation_18/encoder/final_layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 51] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0, Shape: (32, 8), Elements: 256\n",
      "[Layer 52] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 53] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 54] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 55] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 56] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 57] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 58] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 59] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 60] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 61] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 62] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 63] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 64] Name: tft5_for_conditional_generation_18/decoder/block_._0/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 65] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 66] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 67] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 68] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 69] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 70] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 71] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 72] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 73] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 74] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 75] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 76] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 77] Name: tft5_for_conditional_generation_18/decoder/block_._1/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 78] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 79] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 80] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 81] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 82] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 83] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 84] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 85] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 86] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 87] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 88] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 89] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 90] Name: tft5_for_conditional_generation_18/decoder/block_._2/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 91] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 92] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 93] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 94] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 95] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 96] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 97] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 98] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 99] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 100] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 101] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 102] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 103] Name: tft5_for_conditional_generation_18/decoder/block_._3/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 104] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 105] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 106] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 107] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 108] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 109] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 110] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 111] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 112] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 113] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 114] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 115] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 116] Name: tft5_for_conditional_generation_18/decoder/block_._4/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 117] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 118] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 119] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 120] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 121] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 122] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 123] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 124] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 125] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 126] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 127] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 128] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 129] Name: tft5_for_conditional_generation_18/decoder/block_._5/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 130] Name: tft5_for_conditional_generation_18/decoder/final_layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      ">>> Validation Loss after epoch 2: 0.3062937259674072\n"
     ]
    }
   ],
   "source": [
    "# 注入硬件错误\n",
    "tfi.inject(model=model,\n",
    "           confFile=\"/Users/lordtarn1shed/TensorFI2/experiments/layer-states/confFiles/sample.yaml\",\n",
    "           log_level=\"DEBUG\")\n",
    "\n",
    "\n",
    "# 评估故障\n",
    "   # 5.2 验证\n",
    "val_metric = tf.keras.metrics.Mean()\n",
    "for batch in tf_test:\n",
    "    outputs  = model(batch[\"input_ids\"],\n",
    "                     attention_mask=batch[\"attention_mask\"],\n",
    "                     labels=batch[\"labels\"],\n",
    "                     training=False)\n",
    "    val_loss = loss_fn(batch[\"labels\"], outputs.logits)\n",
    "    val_metric.update_state(val_loss)\n",
    "\n",
    "print(f\">>> Validation Loss after epoch {epoch + 1}: {val_metric.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61dca03d-3798-4638-b92c-41e798ff0c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Il s'agit d'un test.\n"
     ]
    }
   ],
   "source": [
    "# 推理示例\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "sample = \"translate English to French: This is a test.\"\n",
    "inp = tokenizer(sample, return_tensors=\"tf\", padding=\"max_length\", max_length=64)\n",
    "with tf.device('/CPU:0'):\n",
    "    out = model.generate(inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"], num_beams=NUM_BEAMS)\n",
    "print(\"Translation:\", tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformer)",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
