{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a51eec-74df-4c53-a8a8-104b5532ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from src import tensorfi2 as tfi\n",
    "\n",
    "# 1. 下载 Tatoeba 英法并只取前 1% 样本以加速实验\n",
    "raw = load_dataset(\"tatoeba\", lang1=\"en\", lang2=\"fr\", split=\"train[:1%]\")  # Tatoeba 英法平行语料 :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "# 2. 初始化分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# 3. 预处理：添加翻译前缀，tokenize，并将 padding token 转为 -100 以忽略\n",
    "def preprocess(examples):\n",
    "    inputs  = [\"translate English to French: \" + ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    mi = tokenizer(inputs,  max_length=64, truncation=True, padding=\"max_length\")\n",
    "    lbl = tokenizer(targets, max_length=64, truncation=True, padding=\"max_length\").input_ids\n",
    "    lbl = [[(t if t != tokenizer.pad_token_id else -100) for t in seq] for seq in lbl]\n",
    "    mi[\"labels\"] = lbl\n",
    "    return mi\n",
    "\n",
    "tokenized = raw.map(preprocess, batched=True, remove_columns=[\"translation\"])  # 动态预处理 :contentReference[oaicite:5]{index=5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b57ec6-156d-442d-8f7b-fe506609e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 21:57:01.917934: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-05-09 21:57:01.917957: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-05-09 21:57:01.917965: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746799021.917975 1876143 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1746799021.917992 1876143 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')  # GPU自动加速\n",
    "\n",
    "# 可定制的超参数\n",
    "MODEL_CHECKPOINT = \"t5-small\"   # 可换成 t5-base、t5-large 等 :contentReference[oaicite:6]{index=6}\n",
    "LEARNING_RATE     = 5e-5\n",
    "NUM_BEAMS         = 4\n",
    "\n",
    "# 加载模型\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)  # 加载预训练 T5 编码器-解码器 :contentReference[oaicite:7]{index=7}\n",
    "\n",
    "# 若需调整层数 / 头数，可在此处重新定义 config\n",
    "# e.g., model.config.num_layers = 4; model.config.num_heads = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71eb64ae-9150-485b-9900-d942eab3c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 166/166 [06:04<00:00,  2.20s/it, loss=0.7484, robust_loss=0.0000]\n",
      "2025-05-09 22:03:34.298600: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after epoch 1: 0.1217\n",
      "\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████| 166/166 [06:09<00:00,  2.23s/it, loss=0.7223, robust_loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after epoch 2: 0.0835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:10:10.209329: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "tf_train =( \n",
    "    tokenized.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    .cache()                        # 缓存到内存/磁盘\n",
    "    .shuffle(2000, reshuffle_each_iteration=True)  # 增加buffer_size\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)  # 异步预取\n",
    "    .repeat()  # 避免每个epoch重新初始化\n",
    ")\n",
    "\n",
    "\n",
    "tf_test = tokenized.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 定义 loss 函数和优化器\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "lambda_weight = 0  # 正则项权重，可调\n",
    "\n",
    "# 训练参数\n",
    "epochs = 2\n",
    "N_samples = len(tokenized)            # 注意是 tokenized，不是 raw\n",
    "batch_size = 16\n",
    "# 正确写法（匹配 drop_remainder=True 后的实际批次数）\n",
    "#steps_per_epoch = N_samples // batch_size  # 整除\n",
    "steps_per_epoch = math.ceil(N_samples / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    train_iter = iter(tf_train)\n",
    "\n",
    "    if epoch >= 1:\n",
    "        lambda_weight = 1e-1  # 正则项权重，可调\n",
    "\n",
    "    pbar = tqdm(range(steps_per_epoch), desc=\"Training\")\n",
    "    for step in pbar:\n",
    "    #for step in range(steps_per_epoch):\n",
    "        batch = next(train_iter)\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # 外层 Tape：用于最终反向传播\n",
    "        with tf.GradientTape() as outer_tape:\n",
    "            # 内层 Tape：用于计算 loss 的梯度\n",
    "            with tf.GradientTape() as inner_tape:\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels, training=True)\n",
    "                \n",
    "                logits = outputs.logits\n",
    "                #loss = loss_fn(labels, logits)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # 计算梯度敏感性鲁棒性正则项（所有参数）\n",
    "            grads = inner_tape.gradient(loss, model.trainable_variables)\n",
    "            # 分层归一：每层求和后除以参数数目\n",
    "            robust_penalty = tf.add_n([\n",
    "                tf.reduce_sum(tf.abs(g)) / tf.cast(tf.size(g), tf.float32)\n",
    "                for g in grads if g is not None\n",
    "            ])\n",
    "\n",
    "            robust_loss = lambda_weight * robust_penalty\n",
    "\n",
    "            \n",
    "            # 将 loss.numpy() 转为 float\n",
    "            loss_val   = float(loss)\n",
    "            robust_val = float(robust_loss)\n",
    "            pbar.set_postfix({\n",
    "                \"loss\":   f\"{loss_val:.4f}\",\n",
    "                \"robust_loss\": f\"{robust_val:.4f}\"\n",
    "            })\n",
    "            \n",
    "\n",
    "            total_loss = loss + robust_loss\n",
    "\n",
    "        # 外层梯度计算：对 total_loss 求导并更新\n",
    "        final_grads = outer_tape.gradient(total_loss, model.trainable_variables)\n",
    "        #optimizer.apply_gradients(zip(final_grads, model.trainable_variables))\n",
    "\n",
    "        clipped_grads = tf.clip_by_global_norm(final_grads, 1.0)[0]  # 全局裁剪\n",
    "        optimizer.apply_gradients(zip(clipped_grads, model.trainable_variables))\n",
    "\n",
    "\n",
    "    # 验证阶段（无扰动）\n",
    "    total_val_loss = 0.0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    for batch in tf_test:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels, training=False)\n",
    "        logits = outputs.logits\n",
    "        val_loss = loss_fn(labels, logits)\n",
    "\n",
    "        total_val_loss += val_loss\n",
    "        num_val_batches += 1\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_val_batches\n",
    "    print(f\"Validation Loss after epoch {epoch + 1}: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1516bc39-bcef-4713-bc72-78b726e4c48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lordtarn1shed/anaconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/tf_utils.py:837: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length.  recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746799810.501293 1876143 service.cc:152] XLA service 0x600001f36f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746799810.501453 1876143 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-09 22:10:10.532090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746799810.737328 1876143 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: C'est un critère.\n"
     ]
    }
   ],
   "source": [
    "# 推理示例\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "sample = \"translate English to French: This is a test.\"\n",
    "inp = tokenizer(sample, return_tensors=\"tf\", padding=\"max_length\", max_length=64)\n",
    "with tf.device('/CPU:0'):\n",
    "    out = model.generate(inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"], num_beams=NUM_BEAMS)\n",
    "print(\"Translation:\", tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f9168-b564-4798-b476-8a4c904e44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Logging level set to DEBUG\n",
      "INFO:root:Starting fault injection in user-specified layer 1\n",
      "INFO:root:Completed injections... exiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable layers (variables): 131\n",
      "[Layer 0] Name: shared/shared/embeddings:0, Shape: (32128, 512), Elements: 16449536\n",
      "[Layer 1] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0, Shape: (32, 8), Elements: 256\n",
      "[Layer 2] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 3] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 4] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 5] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 6] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 7] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 8] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 9] Name: tft5_for_conditional_generation/encoder/block_._0/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 10] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 11] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 12] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 13] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 14] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 15] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 16] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 17] Name: tft5_for_conditional_generation/encoder/block_._1/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 18] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 19] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 20] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 21] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 22] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 23] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 24] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 25] Name: tft5_for_conditional_generation/encoder/block_._2/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 26] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 27] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 28] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 29] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 30] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 31] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 32] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 33] Name: tft5_for_conditional_generation/encoder/block_._3/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 34] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 35] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 36] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 37] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 38] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 39] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 40] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 41] Name: tft5_for_conditional_generation/encoder/block_._4/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 42] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 43] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 44] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 45] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 46] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 47] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._1/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 48] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._1/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 49] Name: tft5_for_conditional_generation/encoder/block_._5/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 50] Name: tft5_for_conditional_generation/encoder/final_layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 51] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0, Shape: (32, 8), Elements: 256\n",
      "[Layer 52] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 53] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 54] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 55] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 56] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 57] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 58] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 59] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 60] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 61] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 62] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 63] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 64] Name: tft5_for_conditional_generation/decoder/block_._0/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 65] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 66] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 67] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 68] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 69] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 70] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 71] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 72] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 73] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 74] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 75] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 76] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 77] Name: tft5_for_conditional_generation/decoder/block_._1/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 78] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 79] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 80] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 81] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 82] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 83] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 84] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 85] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 86] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 87] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 88] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 89] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 90] Name: tft5_for_conditional_generation/decoder/block_._2/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 91] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 92] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 93] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 94] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 95] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 96] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 97] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 98] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 99] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 100] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 101] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 102] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 103] Name: tft5_for_conditional_generation/decoder/block_._3/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 104] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 105] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 106] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 107] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 108] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 109] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 110] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 111] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 112] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 113] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 114] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 115] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 116] Name: tft5_for_conditional_generation/decoder/block_._4/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 117] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._0/SelfAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 118] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._0/SelfAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 119] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._0/SelfAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 120] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._0/SelfAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 121] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._0/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 122] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._1/EncDecAttention/q/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 123] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._1/EncDecAttention/k/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 124] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._1/EncDecAttention/v/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 125] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._1/EncDecAttention/o/kernel:0, Shape: (512, 512), Elements: 262144\n",
      "[Layer 126] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._1/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 127] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._2/DenseReluDense/wi/kernel:0, Shape: (512, 2048), Elements: 1048576\n",
      "[Layer 128] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._2/DenseReluDense/wo/kernel:0, Shape: (2048, 512), Elements: 1048576\n",
      "[Layer 129] Name: tft5_for_conditional_generation/decoder/block_._5/layer_._2/layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "[Layer 130] Name: tft5_for_conditional_generation/decoder/final_layer_norm/weight:0, Shape: (512,), Elements: 512\n",
      "Validation Loss after epoch 2: 0.1063\n"
     ]
    }
   ],
   "source": [
    "# 注入硬件错误\n",
    "tfi.inject(model=model,\n",
    "           confFile=\"/Users/lordtarn1shed/TensorFI2/experiments/layer-states/confFiles/sample.yaml\",\n",
    "           log_level=\"DEBUG\")\n",
    "\n",
    "\n",
    "# 评估故障\n",
    "total_val_loss = 0.0\n",
    "num_val_batches = 0\n",
    "\n",
    "for batch in tf_test:\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels, training=False)\n",
    "    logits = outputs.logits\n",
    "    val_loss = loss_fn(labels, logits)\n",
    "\n",
    "    total_val_loss += val_loss\n",
    "    num_val_batches += 1\n",
    "\n",
    "avg_val_loss = total_val_loss / num_val_batches\n",
    "print(f\"Validation Loss after epoch {epoch + 1}: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61dca03d-3798-4638-b92c-41e798ff0c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: C'est un test.\n"
     ]
    }
   ],
   "source": [
    "# 推理示例\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "sample = \"translate English to French: This is a test.\"\n",
    "inp = tokenizer(sample, return_tensors=\"tf\", padding=\"max_length\", max_length=64)\n",
    "with tf.device('/CPU:0'):\n",
    "    out = model.generate(inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"], num_beams=NUM_BEAMS)\n",
    "print(\"Translation:\", tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformer)",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
